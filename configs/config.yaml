llm:
  model: "llama3.2"
  maxTokens: 1024

logger:
  level: "debug"
  verbose: true 